# LLM_HRI
GPT integrated for verbal human-robot interaction.

## Project Description

This project integrates a large language model (LLM) for verbal human-robot interaction (HRI) in design-fabrication settings. It allows users to issue voice commands to control a robot, interpreting natural language input for movements along the X, Y, and Z axes.

The testing datasets are included in the `TextData` folder.

## Dependencies and Versions

- `openai` 1.35.15
- `playsound` 1.3.0
- `pandas` 2.0.3
- `PyAutoGUI` 0.9.54

You can install them via `pip`

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE.md) file for details.

## Affiliations

- **Lab for Creative Computation (CRCL), EPFL**  
[Website](https://www.crclcrclcrcl.org/)
- **School of Architecture, Princeton University**
[Website](https://soa.princeton.edu/)

## Citation

1. **BibTeX citation**:
@inproceedings{han2025HRILLM,
title={From Words to Actions: A large language model (LLM) approach for human-robot interaction in design-fabrication settings},
author={Han, Isla Xi and Parascho, Stefana},
booktitle={Proceedings of the 30th International Conference on Computer-Aided Architectural Design Research in Asia (CAADRIA 2025)},
address = {Tokyo, Japan},
year={2025},
pubstate={forthcoming},
organization={CAADRIA}
}

2. **APA-style citation**:
Han, Isla Xi and Parascho, Stefana. "From Words to Actions: A Large Language Model (LLM) Approach for Human-Robot Interaction in Design-Fabrication Settings." *Proceedings of the 30th International Conference on Computer-Aided Architectural Design Research in Asia (CAADRIA 2025)*. Tokyo, Japan, 2025. [Forthcoming].

*Feel free to adjust the citation style to match your institution's requirements or personal preferences.*
